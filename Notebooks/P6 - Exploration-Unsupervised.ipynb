{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P6 - Catégorisez automatiquement des questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies classiques\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "# Librairies graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Librairies de traitement de texte\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Méthodes d'import export\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "CT_DIR = '../autotag/save/'\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(CT_DIR + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération et visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = load_obj('all_tags')\n",
    "df_train = pd.read_csv(CT_DIR + 'df_train.csv')\n",
    "df_test = pd.read_csv(CT_DIR + 'df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152855, 2)\n",
      "(38214, 2)\n",
      "(191069, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "dataraw = df_train.append(df_test)\n",
    "print(dataraw.shape)\n",
    "dataraw.head()\n",
    "\n",
    "dataraw = dataraw.sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode non supervisé - Analyse de Title+Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant essayer d'extraire des clusters de notre nouvelle feature, d'abord avec LDA ensuite avec NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "mystops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 15\n",
    "no_top_words = 10\n",
    "\n",
    "# Méthode d'affichage des mots clés de chaque groupe\n",
    "def display_topics(model, feature_names, name, no_top_words, display=True):\n",
    "    total_matches = 0\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if display: print (\"Topic %d \" % (topic_idx), end=' ')\n",
    "        topic_top_words_index = topic.argsort()[:-no_top_words - 1:-1]\n",
    "        n = 0\n",
    "        for i in topic_top_words_index:\n",
    "            if feature_names[i] in all_tags:\n",
    "                n += 1\n",
    "        total_matches += n\n",
    "        if display: print (\"(%d matchs) :\" % (n), end=' ')\n",
    "        if display: print (\" \".join([feature_names[i] for i in topic_top_words_index]))\n",
    "    nmax = no_topics * no_top_words\n",
    "    note = total_matches/nmax\n",
    "    print(\"Note=%.2f (%d matches sur %d possibles - %s)\" % (note, total_matches, nmax, name))\n",
    "    return note\n",
    "\n",
    "def score(vect, mod, name, display=False):\n",
    "    t0 = time()\n",
    "    tf = vect.fit_transform(dataraw['TextCleaned'])\n",
    "    mod.fit(tf)\n",
    "    if display: print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    note = display_topics(mod, vect.get_feature_names(), name, no_top_words, display=display)\n",
    "    \n",
    "    if display: \n",
    "        print()\n",
    "        predict = mod.transform(tf)\n",
    "        for n in range(10):\n",
    "            topic_most_pr = predict[n].argmax()\n",
    "            print(\"doc {}, topic {}, {}...\".format(n, topic_most_pr, dataraw.TextCleaned.iloc[n][:50]))\n",
    "    \n",
    "    return note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA avec CountVectorizer\n",
    "\n",
    "def scoreLDA(max_df, min_df, max_features, display=False):\n",
    "    vect = CountVectorizer(max_df=max_df, min_df=min_df, max_features=max_features, stop_words='english')\n",
    "\n",
    "    mod = LatentDirichletAllocation(n_components=no_topics, max_iter=10, learning_method='online', \n",
    "                                    learning_offset=50., random_state=0)\n",
    "    name = 'LDA max=%.1f - min=%i - feat=%i' % (max_df, min_df, max_features)\n",
    "    return score(vect, mod, name, display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF avec TfidfVectorizer\n",
    "\n",
    "def scoreNMF(max_df, min_df, max_features, loss='frobenius', display=False):\n",
    "    vect = TfidfVectorizer(max_df=max_df, min_df=min_df, max_features=max_features, stop_words='english')\n",
    "\n",
    "    mod = NMF(n_components=no_topics, alpha=.1, l1_ratio=.5, beta_loss=loss, solver='mu', max_iter=200, random_state=0)\n",
    "    name = 'NMF max=%.1f - min=%i - feat=%i' % (max_df, min_df, max_features)\n",
    "    return score(vect, mod, name, display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN\n",
      "Note=0.51 (77 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=10000)\n",
      "Note=0.47 (70 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=10000)\n",
      "Note=0.44 (66 matches sur 150 possibles - LDA max=0.8 - min=10 - feat=10000)\n",
      "Note=0.48 (72 matches sur 150 possibles - NMF max=0.8 - min=10 - feat=10000)\n",
      "Note=0.47 (70 matches sur 150 possibles - LDA max=0.8 - min=20 - feat=10000)\n",
      "Note=0.48 (72 matches sur 150 possibles - NMF max=0.8 - min=20 - feat=10000)\n",
      "MAX\n",
      "Note=0.42 (63 matches sur 150 possibles - LDA max=0.5 - min=5 - feat=10000)\n",
      "Note=0.49 (74 matches sur 150 possibles - NMF max=0.5 - min=5 - feat=10000)\n",
      "Note=0.51 (77 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=10000)\n",
      "Note=0.47 (70 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=10000)\n",
      "Note=0.51 (77 matches sur 150 possibles - LDA max=0.9 - min=5 - feat=10000)\n",
      "Note=0.47 (70 matches sur 150 possibles - NMF max=0.9 - min=5 - feat=10000)\n",
      "FEATURES\n",
      "Note=0.45 (68 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=1000)\n",
      "Note=0.45 (67 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=1000)\n",
      "Note=0.51 (77 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=10000)\n",
      "Note=0.47 (70 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=10000)\n",
      "Note=0.47 (71 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=100000)\n",
      "Note=0.50 (75 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=100000)\n",
      "NMF loss\n",
      "Note=0.47 (70 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=10000)\n",
      "Note=0.39 (58 matches sur 150 possibles - NMF max=0.8 - min=5 - feat=10000)\n",
      "done in 5288.812s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"MIN\")\n",
    "p_min = [5, 10, 20]\n",
    "for m in p_min:\n",
    "    scoreLDA(.8, m, 10000)\n",
    "    scoreNMF(.8, m, 10000)\n",
    "print(\"MAX\")\n",
    "p_max = [.5, .8, .9]\n",
    "for m in p_max:\n",
    "    scoreLDA(m, 5, 10000)\n",
    "    scoreNMF(m, 5, 10000)\n",
    "print(\"FEATURES\")\n",
    "p_feat = [1000, 10000, 100000]\n",
    "for m in p_feat:\n",
    "    scoreLDA(.8, 5, m)\n",
    "    scoreNMF(.8, 5, m)\n",
    "\n",
    "print(\"NMF loss\")\n",
    "scoreNMF(.8, 5, 10000, loss='frobenius')\n",
    "scoreNMF(.8, 5, 10000, loss='kullback-leibler')\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 736.365s.\n",
      "Topic 0  (7 matchs) : file line use text string data print read output format\n",
      "Topic 1  (3 matchs) : test date 10 key 00 2009 time unit 12 datetim\n",
      "Topic 2  (5 matchs) : page html form asp control javascript text id function click\n",
      "Topic 3  (5 matchs) : file window use run project applic instal work visual version\n",
      "Topic 4  (4 matchs) : tabl sql databas queri data row column id select use\n",
      "Topic 5  (6 matchs) : list user view item id model field key custom select\n",
      "Topic 6  (2 matchs) : error messag log event tri session connect rubi assembl bar\n",
      "Topic 7  (5 matchs) : imag width div style color height text bind li background\n",
      "Topic 8  (5 matchs) : thread product report process program start time excel year day\n",
      "Topic 9  (5 matchs) : java xml org eclips apach class com xsl jar hibern\n",
      "Topic 10  (1 matchs) : use like way need code know applic look want net\n",
      "Topic 11  (6 matchs) : number match express point doubl regex anim draw frame algorithm\n",
      "Topic 12  (7 matchs) : librari load memori flash bit function json flex video world\n",
      "Topic 13  (7 matchs) : class object string public return new int method function valu\n",
      "Topic 14  (9 matchs) : server servic web http php com request client url use\n",
      "Note=0.51 (77 matches sur 150 possibles - LDA max=0.8 - min=5 - feat=10000)\n",
      "\n",
      "doc 0, topic 3, unabl start django server comput export path djang...\n",
      "doc 1, topic 10, commerci use googl api question mayb better fit bu...\n",
      "doc 2, topic 1, anoth linq pivot problem convert sql script linq q...\n",
      "doc 3, topic 4, limit global memori resourc oracl 10g databas serv...\n",
      "doc 4, topic 13, visual studio shortcut automat creat constructor i...\n",
      "doc 5, topic 3, asp net search subdirectori search sub directori a...\n",
      "doc 6, topic 1, get row start end time start end time anoth row sq...\n",
      "doc 7, topic 10, free python debugg watchpoint pdb winpdb seem miss...\n",
      "doc 8, topic 14, wcf servic activ directori authent write wcf servi...\n",
      "doc 9, topic 7, authent activ directori use python ldap authent ad...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5133333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Détail du meilleur modèle\n",
    "scoreLDA(.8, 5, 10000, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
